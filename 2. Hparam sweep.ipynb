{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использованные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "a3rmOh1oCLJH",
    "outputId": "99a73ce9-0770-4a92-88ef-f6c019107f89",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from models import MLP, Transformer\n",
    "from utils import mlp_params, gpt_params, g_transform\n",
    "from datagen import SubLoader, TaskAugmentor\n",
    "from pl_base import BestValidCallback\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перебор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Первая важная вещь, которую делают в статье - это сравнение перцептрона и трансформера, как мета-моделей. Заявляется, что первый, сколько бы параметров у него не было, может только запоминать таски, а не обобщать. Трансформер наоборот должен уметь находить какие-то общие паттерны для всех тасок, благорадя которым он может работать хорошо на любом датасете. Демонстрирует это вот такая хитмапа:\n",
    "<img src=\"https://cdn.discordapp.com/attachments/674191702906503199/1194322630292025394/image.png?ex=65afeea0&is=659d79a0&hm=4fab9e68c5d4c47d5f40599f0b341a9e0efa365bf35c14fd237191cb1e1c3705&\">\n",
    "Трансформер действительно что-то выучиывает, но на новых данных у него всё грустно (они впрочем этого не показывают вот здесь, зато я покажу), а трансформер - наоборот, это настоящее чудо\n",
    "\n",
    "Это заявление мы будем проверять таким образом:\n",
    "1. За модельки я возьму перцептрон с 2 скрытыми слоями и одним выходным, меняться у него будет только размерность скрытого слоя, и decoder-only трансформер, у которого меняю размер эмбеддингов. В качестве инпута будут выпрямленные 28x28x1 картинки из MNIST. Батч сайз 128, в статье 512, но у меня на таком ничего не получилось\n",
    "2. В качестве датасета я возьму аугментированный $N_n$ раз MNIST. Сколько сэмплов брать, это вопрос очень интересный, в статье про это ни слова. Для MLP я возьму какое-то фиксированное число, а для трансформера по одному из каждой таски, этого будет достаточно, потому что в одной последовательности уже 100 примеров\n",
    "   `train_loader` - MNIST, на котором тренируемся,\n",
    "   `valid_loader` - другой мнист, с другими сэмплами, но с теми же тасками, на нём валидируемся,\n",
    "   `test_loader` - тоже другой мнист, но теперь и с тасками другими, на нём тестим\n",
    "3. Число тасок я буду перебирать по сетке с шагом в 2. В статье с шагом 1, но у меня нет столько времени. Для теста и валидации число равно $\\log_2N_n$, чтобы не получилось слишком много. Сэмпл тоже 1, если трансформер, либо же 0.2, если MLP\n",
    "4. Размер модели это тоже тонкая вещь. Для перцептрона понятно, что это размер хидден слоя. Для трансформера не так прозрачно. Он получается, как `hidden_size * n_heads * * 4`, и просто так его перебирать тяжко. Поэтому я решил забить и итерируюсь только по `hidden_size`\n",
    "5. Для оптимизации перцептрона я не буду брать ничего хитрого, для трансформера хитрить придётся. В статье пишут, что на больших размерах тасок лосс выходит на плато, это чистая правда. Бороться с этим я буду по-своему - через оптимайзер и шедулер, кажется, что более-менее успешно\n",
    "\n",
    "Остальное: параметры, функцию трейна, архитекруту моделек лучше посмотреть в коде внизу, либо в модулях. Ниже только код для обучения и получившиеся результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерпретация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы было поменьше копипасты, я засунул кусок с генерацией в отдельную функцию. Она делает 3 аугментора для каждого из 3 датасетов, 2 из них с одинковым сидом - это seen таски, третий с другим - это unseem, и также 3 лоадера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(n_tasks, draw_sequence, batch_size, seed=69):\n",
    "\n",
    "    # samples and augmentor\n",
    "    train_samples = 1 if draw_sequence else min(60000*n_tasks, 1000000)\n",
    "    test_samples = 1 if draw_sequence else min(60000*n_tasks, 100000)\n",
    "    train_augmentor = TaskAugmentor(\n",
    "        n_tasks, draw_sequence=draw_sequence, random_state=seed\n",
    "    )\n",
    "    seen_augmentor = TaskAugmentor(\n",
    "        int(np.log2(n_tasks)), draw_sequence=draw_sequence, random_state=seed\n",
    "    )\n",
    "    unseen_augmentor = TaskAugmentor(\n",
    "        int(np.log2(n_tasks)), draw_sequence=draw_sequence, random_state=seed+1\n",
    "    )\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_augmentor.transform(mnist_train, train_samples),\n",
    "        batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        seen_augmentor.transform(mnist_test, test_samples),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        unseen_augmentor.transform(mnist_test, test_samples),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST, из которого я буду сэмплить, оптимайзеры, трансформы, это всё одинаковое вне зависимости от конфигурации, поэтому их я собираю отдельно в `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_train = SubLoader(MNIST('./datasets', train=True, transform=g_transform)) \n",
    "mnist_test = SubLoader(MNIST('./datasets', train=True, transform=g_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец остаётся только запустить цикл и идти пить чай. По-хорошему это нужно делать для нескольких сидов, но на это нужно время. Результаты на всякий случай засылались в том числе и на [wandb](https://wandb.ai/lerostre/gpicl/runs/i57grjqb/overview?workspace=user-lerostre), хотя там не очень информативно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже консервирует параметры, которые менять всё же не следует. Что поменять можно:\n",
    "название модели, но в статье это делается только для двух, если надо что-то ещё, можно засунуть прямо в код, батч сайз, логгирование в wandb, таски для перебора, hidden size для перебора, суффикс для выходного файла, сид (у меня опять один, мне лень), а также прочие параметры для тренера, если это нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log_loop(\n",
    "    model_name=\"gpt\",\n",
    "    batch_size=128,\n",
    "    logger=False,\n",
    "    n_tasks_list=2**np.arange(0, 19, 2),\n",
    "    hid_size_list=2**np.arange(0, 10),\n",
    "    output_file_suffix=\"\",\n",
    "    random_state=0,\n",
    "    **trainer_arguments\n",
    "):\n",
    "    # each model has its own metric df\n",
    "    log = pd.DataFrame(columns=[\"model\", \"dataset\", \"n_tasks\", \"accuracy\", \"hid_size\"])\n",
    "    \n",
    "    for n_tasks in n_tasks_list:\n",
    "        #each task has its own loader\n",
    "        loaders = augment_data(\n",
    "            n_tasks, draw_sequence=True,\n",
    "            batch_size=batch_size, seed=random_state\n",
    "        )\n",
    "        train_loader, valid_loader, test_loader = loaders\n",
    "        \n",
    "        for hid_size in hid_size_list:\n",
    "            # different models are differently initialised\n",
    "            if model_name == \"gpt\":\n",
    "                config = GPT2Config(\n",
    "                    num_labels=10, hidden_size=int(hid_size), n_inner=int(4*hid_size),\n",
    "                    n_layer=4, n_head=1, n_positions=100,\n",
    "                )\n",
    "                model = GPT(config=config, **params))\n",
    "                # number of epochs can be changed if necessary but best not to\n",
    "                training_config = {\"max_steps\": 100000}\n",
    "            elif model_name == \"mlp\":\n",
    "                model = MLP(hidden_size=hid_size, **params)\n",
    "                training_config = {\"max_epochs\": 10}\n",
    "                \n",
    "            # init wandb run for given model\n",
    "            wandb_logger = None\n",
    "            if logger:\n",
    "                # config is a bit clunky to track\n",
    "                name = f\"{model_name}_{n_tasks}_{hid_size}\"\n",
    "                # for param, param_value in model_kwargs.items():\n",
    "                #     name += f\"__{param}_{param_value}\"\n",
    "                # wandb_config = {\n",
    "                #     \"name\": model_name,\n",
    "                # }\n",
    "                # wandb_config.update(trainer_arguments)\n",
    "                # wandb_config.update(training_arguments)\n",
    "                wandb.init(\n",
    "                    project=\"gpicl\", name=name, tags=[model_name],\n",
    "                    # config=wandb_config\n",
    "                )\n",
    "                wandb_logger = WandbLogger(log_model=False)\n",
    "        \n",
    "            # train and store\n",
    "            trainer = pl.Trainer(\n",
    "                precision=\"16\",\n",
    "                accelerator=\"gpu\",\n",
    "                logger=wandb_logger,\n",
    "                enable_progress_bar=False,\n",
    "                enable_model_summary=False,\n",
    "                **trainer_arguments, **training_config\n",
    "            )\n",
    "            trainer.fit(model, train_loader, valid_loader)\n",
    "            logs = trainer.callback_metrics\n",
    "            logs.update(trainer.test(model, test_loader, verbose=False)[0])\n",
    "            logs[\"valid_accuracy\"] = model.best_valid_acc\n",
    "            \n",
    "            clear_output(True)\n",
    "\n",
    "            # fill df with metrics\n",
    "            for name, metric in train_results.items():\n",
    "                if \"accuracy\" in name:\n",
    "                    dataset = name.split(\"_\")[0]\n",
    "                    if isinstance(metric, torch.Tensor):\n",
    "                        metric = metric.item()\n",
    "                    log.loc[log.shape[0]] = (model_name, dataset, n_tasks, metric, hid_size)\n",
    "                    log.to_csv(f\"experiments/{model_name}_log{output_file_suffix}.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215dd92413134707aa919d7bb23a598e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating tasks:   0%|          | 0/262144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in [\"mlp\", \"gpt\"]:\n",
    "    train_log_loop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё сделано правильно, то в папке должны были появиться 2 лога для перцептрона и трансформера. Осталось их считать и построить очень красивый график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "from IPython.display import display, HTML\n",
    "from plotly.subplots import make_subplots\n",
    "from itertools import product\n",
    "\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(HTML(\n",
    "    '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "))\n",
    "\n",
    "def df_to_plotly(df):\n",
    "    return {'z': df.accuracy.tolist(),\n",
    "            'x': df.hid_size.astype(str).tolist(),\n",
    "            'y': df.n_tasks.astype(str).tolist()}\n",
    "\n",
    "titles = [\n",
    "    f'{model}, {seen} MNIST' for model, seen\n",
    "    in product(['MLP', 'Transformer'], ['seen', 'unseen'])\n",
    "]\n",
    "seen_mapper = {\"valid\": \"seen\", \"test\": \"unseen\"}\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    shared_yaxes=True,\n",
    "    subplot_titles=tuple(titles),\n",
    "    vertical_spacing = 0.15\n",
    ")\n",
    "\n",
    "log_cols = ['model', 'dataset', 'n_tasks', 'hid_size', 'accuracy']\n",
    "for i, model in enumerate(['MLP', 'Transformer']):\n",
    "    for j, seen in enumerate([\"seen\", \"unseen\"]):\n",
    "        sublog = pd.read_csv(f\"experiments/{model.lower()}_log.csv\")\n",
    "        sublog = sublog.sort_values(['n_tasks', 'hid_size'])\n",
    "        sublog[\"dataset\"] = sublog.dataset.map(seen_mapper)\n",
    "        sublog = sublog[sublog.dataset == seen]\n",
    "        plotly_df = df_to_plotly(sublog)\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            **plotly_df, coloraxis=\"coloraxis\", zmin=0, zmax=1,\n",
    "        ), row=i+1, col=j+1)\n",
    "        \n",
    "for i in [1, 3]:\n",
    "    fig[\"layout\"][f\"yaxis{i}\"].update(\n",
    "        title_text='number of tasks', tickmode='array',\n",
    "        tickvals = np.sort(np.unique(plotly_df[\"y\"]).astype(int)),\n",
    "        ticktext = [f\"$2^{{{i}}}$\" for i in range(0, 17, 2)]\n",
    "    )\n",
    "fig.update_xaxes(\n",
    "    title_text='hidden size', showgrid=False,\n",
    "    tickvals = np.sort(np.unique(plotly_df[\"x\"]).astype(int)),\n",
    "    ticktext = [f\"${i}$\" for i in np.sort(np.unique(plotly_df[\"x\"]).astype(int))]\n",
    ")\n",
    "fig.update_yaxes(showgrid=False)\n",
    "fig.update_layout(\n",
    "    height=700, width=700,\n",
    "    coloraxis={\"colorbar\":dict(title=\"Accuracy\"), 'colorscale':'Brwnyl'},\n",
    "    plot_bgcolor=\"#E6D7BD\", title=\"Performance on seen and unseen tasks\"\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.discordapp.com/attachments/674191702906503199/1194467621245030450/newplot_3.png?ex=65b075a9&is=659e00a9&hm=6719ed2f15771a23e129217786f360e03372fd842fadaca0f0834dd4b64d8be4&\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложно сказать, получилось ли то же, потому что в статье нет чётких цифр. Можно видеть, что эта штука реально работает, почему=то, картинка похожа. Другое дело, что качество на самом-то деле не очень большое - в районе 0.5 аккураси, но тот факт, что но вообще научилось обобщать, это конечно поразительно. На графике если что есть наны, всё-таки я не все параметры перебрал, да и тех, что есть чуть меньше, но всё сочное должно тут быть"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
