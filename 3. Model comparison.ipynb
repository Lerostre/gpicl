{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использованные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это нужно для одной из моделей, но не факт, что успешно поставится\n",
    "!pip install learn2learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "a3rmOh1oCLJH",
    "outputId": "99a73ce9-0770-4a92-88ef-f6c019107f89",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10, KMNIST, SVHN\n",
    "from models import MLP, LSTM, Transformer\n",
    "from datagen import SubLoader, TaskAugmentor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, насколько трансформер вообще хорош, нужно понять, насколько остальные модели плохи. Идея метатеста в статье довольно странная из того, что я понял. Суть в том, что модель должна увидеть 99 примеров из одной таски и сделать предсказание на 100. Если всё хорошо - модель научилась извлекать новую информацию. Если нет - то нет. При этом алгоритм немного разный, в зависимости от модели, но обо всём по порядку. Чёткого описания в статье разумеется нет. Референсом служит вот такая таблица\n",
    "\n",
    "<img width=\"700px\" src=\"https://cdn.discordapp.com/attachments/674191702906503199/1194436697258196992/image.png?ex=65b058dc&is=659de3dc&hm=730df59553279d76ef794f920bbe03b5f2837cf8424e1ccb77711d36d5676bcf&\">\n",
    "\n",
    "Я буду делать для всех датасетов, кроме рандомного, потому что я так и не понял, как его нужно собирать. Там было что-то про сэмплирование из равномерного распределения, но я уже как-то слишком устал\n",
    "\n",
    "Для метатеста нужно \"просмотреть\" 99 примеров и сделать предсказание на 100. Для rnn это более-менее понятно - сделать предсказание с маской, а вот для перцептрона не так очевидно. Как я понимаю, достаточно сделать GD на 99 и предсказать на 100, так и поступим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    g_transform, cifar_transform, svhn_transform,\n",
    "    mlp_params, lstm_params, gpt_params\n",
    ")\n",
    "from models import MLP, GPT, LSTM\n",
    "# from learn2learn.algorithms import LightningMAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "Функция трейна будет очень большая, потому что алгоритм отличается сильно. Что нам нужно сделать, так это удостоваериться, что датасет прочитается, какой бы он ни был, за это отвечает `get_test_sets`, написать аккураси для rnn - предсказывать по 99 100-й, и аккураси для mlp - выучить 99, предсказать 100-й. Возвращают они немного разное, как-то лень это всё унифицировать, сделаем позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sets(dataset, transform):\n",
    "    try:\n",
    "        to_see = SubLoader(dataset('./datasets', split=\"train\", transform=transform)) \n",
    "        to_predict = SubLoader(dataset('./datasets', split=\"test\", transform=transform)) \n",
    "    except:\n",
    "        to_see = SubLoader(dataset('./datasets', train=True, transform=transform)) \n",
    "        to_predict = SubLoader(dataset('./datasets', train=False, transform=transform))\n",
    "    return to_see, to_predict\n",
    "\n",
    "def sequence_last_acc_rnn(model, loader, model_name):\n",
    "    if model_name == \"gpt\":\n",
    "        attention_mask = torch.zeros(len(loader), 100)\n",
    "        attention_mask[:, :99] = 1\n",
    "        pred = F.softmax(\n",
    "            model(loader.dataset.data, attention_mask=attention_mask), 1\n",
    "        ).argmax(1)\n",
    "    elif model_name == \"lstm\":\n",
    "        pred = F.softmax(model(loader.dataset.data), 1).argmax(1)\n",
    "    res = (pred[:, -1] == loader.dataset.targets[:, -1]).float().mean()\n",
    "    return {\"valid_accuracy\": res.item()}\n",
    "    \n",
    "def sequence_last_acc_mlp(to_see, to_predict):\n",
    "    trainer = pl.Trainer(\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "        max_epochs=1, accelerator=\"gpu\",\n",
    "    )\n",
    "    trainer.fit(model, test_to_see, test_to_predict)\n",
    "    return trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец функция трейна. Ведёт себя по-разному в зависимости от модели. Можно фиксировать сид, я делал на 3 разных, варьировать батчи, число тестовых тасок здесь это замена сиду - они все разные, и суффикс для сохранения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def last_accuracy_evaluation(\n",
    "    model_name,\n",
    "    random_state=69,\n",
    "    batch_size=128,\n",
    "    n_train_tasks=2**16,\n",
    "    n_test_tasks=256,\n",
    "    output_file_suffix=\"\",\n",
    "    **trainer_arguments\n",
    "):   \n",
    "    logs = []\n",
    "    # draw train distribution which is always augmented mnist\n",
    "    mnist = SubLoader(MNIST('./datasets', train=True, transform=g_transform))\n",
    "    draw_sequence = True if model_name in [\"lstm\", \"gpt\"] else False\n",
    "    train_augmentor = TaskAugmentor(\n",
    "        n_tasks=n_train_tasks,\n",
    "        random_state=random_state,\n",
    "        draw_sequence=draw_sequence\n",
    "    )\n",
    "    train = train_augmentor.transform(mnist, n_samples=1)\n",
    "    meta_train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # define model among given choices or add your own\n",
    "    model = {\n",
    "        \"mlp\": MLP(**mlp_params),\n",
    "        # \"maml\": LightningMAML(MLP(**mlp_params), lr=0.1), requires learn2liearn lib\n",
    "        \"lstm\": LSTM(**lstm_params),\n",
    "        \"gpt\": GPT(**gpt_params)\n",
    "    }[model_name]\n",
    "\n",
    "    # training config differs for each model\n",
    "    training_config = {\"max_steps\": 100000}\n",
    "    if model_name in [\"mlp\", \"maml\"]:\n",
    "        training_config = {\"max_epochs\": 10}\n",
    "    trainer = pl.Trainer(\n",
    "        enable_model_summary=False,\n",
    "        accelerator=\"gpu\",\n",
    "        callbacks=[EarlyStopping(\n",
    "            monitor=\"train_accuracy\",\n",
    "            min_delta=0.025,\n",
    "            patience=100,\n",
    "            mode=\"max\"\n",
    "        )], **training_config, **trainer_arguments\n",
    "    )\n",
    "    trainer.fit(model, meta_train)\n",
    "\n",
    "    # calculate accuracy on unseen datasets\n",
    "    for dataset, transform, dataset_name in zip(\n",
    "        [MNIST, FashionMNIST, KMNIST, CIFAR10, SVHN],\n",
    "        [g_transform]*3+[cifar_transform, svhn_transform],\n",
    "        [\"MNIST\", \"FashionMNIST\", \"KMNIST\", \"CIFAR10\", \"SVHN\"]\n",
    "    ):\n",
    "        test_augmentor = TaskAugmentor(\n",
    "            n_tasks=n_test_tasks,\n",
    "            draw_sequence=draw_sequence,\n",
    "            random_state=random_state-1\n",
    "        )\n",
    "        # to see is either an unseen sequence or sequence to memorize for mlp\n",
    "        to_see, to_predict = get_test_sets(dataset, transform)\n",
    "        to_see_samples = 99 if model_name in [\"mlp\", \"maml\"] else 1\n",
    "        to_see = test_augmentor.transform(to_see, n_samples=to_see_samples)\n",
    "        to_see = DataLoader(to_see, batch_size=1, shuffle=False)\n",
    "\n",
    "        # perform GD for mlp or browse for rnn\n",
    "        if model_name in [\"lstm\", \"gpt\"]:\n",
    "            last_accuracy_entry = sequence_last_acc_rnn(model, to_see, model_name)\n",
    "        elif model_name in [\"mlp\", \"maml\"]:\n",
    "            to_predict = test_augmentor.transform(to_predict, n_samples=1)\n",
    "            to_predict = DataLoader(to_predict, batch_size=1, shuffle=False)\n",
    "            last_accuracy_entry = sequence_last_acc_mlp(to_see, to_predict)\n",
    "\n",
    "        # store and update logs\n",
    "        entry = {\n",
    "            \"model_name\": model_name,\n",
    "            \"trained_on\": train_dataset_name,\n",
    "            \"dataset\": dataset_name,\n",
    "        }\n",
    "        entry.update(last_accuracy_entry)\n",
    "        logs.append(entry)\n",
    "        pd.DataFrame(logs).to_csv(\n",
    "            f\"experiments/metatest_{model_name}{output_file_suffix}.csv\", index=0\n",
    "        )\n",
    "        \n",
    "    clear_output(True)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я делал для 16 тасок в случае перцептрона - вспоминаем график из `2. Hparams sweep.ipynb`, там этого было достаточно, чтобы обучиться, а для rnn беру $2^{14}$, там как раз происходит фазовый переход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"mlp\", \"maml\", \"lstm\", \"gpt\"]:\n",
    "    n_tasks = 16 if model in [\"mlp\", \"maml\"] else 2**14\n",
    "    last_accuracy_evaluation(model_name, n_train_tasks=n_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretaion\n",
    "Теперь приятная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv(f\"experiments/metatest_{dataset}.csv\")\n",
    "    for dataset in [\"mlp\", \"lstm\", \"gpt\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">valid_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>MNIST</th>\n",
       "      <th>FashionMNIST</th>\n",
       "      <th>KMNIST</th>\n",
       "      <th>CIFAR10</th>\n",
       "      <th>SVHN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.095052</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.102865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt</th>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.350260</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.088542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           valid_accuracy                                           \n",
       "dataset             MNIST FashionMNIST    KMNIST   CIFAR10      SVHN\n",
       "model_name                                                          \n",
       "mlp              0.370968     0.225806  0.096774  0.081967  0.049180\n",
       "lstm             0.109375     0.095052  0.098958  0.104167  0.102865\n",
       "gpt              0.523438     0.458333  0.350260  0.114583  0.088542"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_order = [\n",
    "    ('valid_accuracy', x) for x in\n",
    "    [\"MNIST\", \"FashionMNIST\", \"KMNIST\", \"CIFAR10\", \"SVHN\"]\n",
    "]\n",
    "index_order = [\"mlp\", \"lstm\", \"gpt\"]\n",
    "\n",
    "summary = (\n",
    "    df.groupby([\"model_name\", \"dataset\"]) \\\n",
    "    .mean(\"valid_accuracy\") \\\n",
    "    .reset_index() \\\n",
    "    .pivot(index=\"model_name\", columns=\"dataset\") \\\n",
    "    # .reindex(col_order, axis=1) \\\n",
    "    # .reindex(index_order, axis=0)\n",
    ")\n",
    "summary.loc[index_order, col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мои результаты вышли не такими впечатляющими с точки зрения цифр, но одну вещь в них всё равно видно. MLP ещё что-то может из себя выдавить, если датасет похож, потому что он его тупо запоминает. LSTM ни рыба, ни мясо, хотя он был у меня не такой, как в статье. А вот трансформер это совсем другое дело, хотя на цветных датасетах он всё-таки не очень себя показал"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
