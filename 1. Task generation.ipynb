{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использованные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "a3rmOh1oCLJH",
    "outputId": "99a73ce9-0770-4a92-88ef-f6c019107f89",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем лететь ставить эксперименты, нужно разобраться с тем, как же всё-таки генерировать новые таски из имеющегося датасета. Учитывая, что их число может доходить до $2^{24}$, это не так просто"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сперва нужны сами датасеты. Для примера возьмём MNIST, для него же нужно будет собрать трансформации.\n",
    "   Они здесь написано костыльно, просто потому что вдруг что-то сломается, но суть такая: берём картинку,\n",
    "   плодим каналы, поскольку она чёрно-белая, ресайзим, транспонируем каналы, чтобы потом её нормально распрямить, кастим во флоты. Трансформация ниже по факту оставляет форму картинки, как есть, но понятно, что это легко поменять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "g_transform = v2.Compose([\n",
    "    v2.Lambda(lambda x: x.repeat(3, 1, 1, 1)),\n",
    "    v2.Resize(28),\n",
    "    v2.Lambda(lambda x: x.transpose(0, 1)),\n",
    "    v2.Grayscale(),\n",
    "    v2.Lambda(lambda x: x.flatten(1)),\n",
    "    v2.ConvertImageDtype(torch.float),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня все датасеты заворачиваются в мой класс, который просто чуть удобнее применяет трансформации и делает общий интерфейс для всех датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "                 Lambda(<lambda>, types=['object'])\n",
       "                 Resize(size=[28], interpolation=InterpolationMode.BILINEAR, antialias=warn)\n",
       "                 Lambda(<lambda>, types=['object'])\n",
       "                 Grayscale(num_output_channels=1)\n",
       "                 Lambda(<lambda>, types=['object'])\n",
       "                 ConvertImageDtype()\n",
       "           )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datagen import SubLoader\n",
    "\n",
    "mnist_train = SubLoader(MNIST(\n",
    "    './datasets', train=True, download=True, transform=g_transform\n",
    ")) \n",
    "mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Следующий шаг это применить какую-нибудь аугментацию и посмотреть, что с ним станет\n",
    "\n",
    "Напомню, что в статье трансформацией датасета считается\n",
    "<img src=\"https://media.discordapp.net/attachments/674191702906503199/1194320451283980349/image.png?ex=65afec98&is=659d7798&hm=c9b27e967024dc88b819a2ccb80aac09d14fd49db607efcc4feb1aa202279037&=&format=webp&quality=lossless&width=749&height=457\" width=\"500px\">\n",
    "\n",
    "$D_{\\text{orig}} = \\{x_i, y_i\\}_{i=1}^{N_D}$ - старый датасет \\\n",
    "$D = \\{A_{n}x_i, p_n(y)_i\\}_{(i=1, \\ n=1)}^{(N_D, \\ N_n)}$ - новый датасет \\\n",
    "$A \\in \\mathbb{R}^{N_x}, A_{ij} \\in \\mathcal{N}(0,\\,\\frac{1}{N_x})$ - линейный проектор \\\n",
    "$p(y) \\in S_{N_y}$ - перестановка на множестве таргетов \\\n",
    "$N_D$ - размерность всего датасета, например 60к картинок из MNIST \\\n",
    "$N_n$ - число новых тасок \\\n",
    "$N_x$ - размерность входных данных, в нашем случае картинок \\\n",
    "$N_y$ - число классов таргета \\\n",
    "$Ax_i$ - проекция $i$-го объекта \\\n",
    "$p(y)_i$ - $i$-ый таргет после перестановки. Важно(!) я не делаю onehot специально, потому что использую кросс-энтропию\n",
    "\n",
    "Матриц и перестановок должно быть столько, сколько новых тасок мы хотим нагенерить, потом их склеиваем в один большой датасет и обучаем что-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) -> torch.Size([240000, 784])\n",
      "torch.Size([60000]) -> torch.Size([240000])\n"
     ]
    }
   ],
   "source": [
    "from datagen import TaskAugmentor\n",
    "\n",
    "augmentor = TaskAugmentor(\n",
    "    n_tasks=4, draw_sequence=False, random_state=69, device=\"cpu\"\n",
    ")\n",
    "# не нормируем, иначе не сравним\n",
    "augmented_mnist = augmentor.transform(mnist_train, normalize=False)\n",
    "print(f\"{mnist_train.data.shape} -> {augmented_mnist.data.shape}\")\n",
    "print(f\"{mnist_train.targets.shape} -> {augmented_mnist.targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все они генерируют строго те же самые трансформации, если зафксировать сид. Сделано это по-колхозному, но мне главное, что работает. Проверим, что проекция и перестановка действительно применяются к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1272380470, 1724767435, 3474919369, 2559044203])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentor._generation_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagen import LinearProjection, TargetPermutation\n",
    "\n",
    "projection = LinearProjection(28*28*1, random_state=1272380470)\n",
    "permutation = TargetPermutation(10, random_state=1272380470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.1410e-06), tensor(0.0013), 0.0012755102040816326)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# всё, как надо по статье\n",
    "m = projection.transformation_matrix\n",
    "m.mean(), m.std(), 1/784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём картинку и таргет. Автотрансформ от торчивжна там отключён, потому что он применяется\n",
    "лишь к одному объекту, а не ко всем сразу, как этого хочется. Надо сделать вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), tensor(5))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, target = mnist_train.transform(mnist_train[0])\n",
    "image.shape, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.allclose(projection(image), augmented_mnist.data[0]),\n",
    " torch.allclose(permutation(target), augmented_mnist.targets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем то, что нужно \\\n",
    "Для последовательностей всё чуть-чуть хитрее. Они все сэмплируются по умолчанию, просто потому что иначе будет слишком большая последовательность. Идея статьи в том, чтобы подавать их все сразу в один аттеншн, а 60к картинок туда не влезут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "augmentor = TaskAugmentor(\n",
    "    n_tasks=4, draw_sequence=True, random_state=69, device=\"cpu\"\n",
    ")\n",
    "# не нормируем, иначе не сравним\n",
    "augmented_mnist_seq = augmentor.transform(mnist_train, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 100, 794]), torch.Size([4, 100]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_mnist_seq.data.shape, augmented_mnist_seq.targets.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут специально тест написать будет посложнее, поэтому я не хочу этим заниматься, но по логике кода всё должно быть верно. Также, как видно по размерности, к инпуту приклеиваются onehot-таргеты, сдвинутые вправо, как на картинке, чтобы учиться предсказывать по произвольному префиксу тоже \\\n",
    "<img src=\"https://media.discordapp.net/attachments/674191702906503199/1194319105839333478/image.png?ex=65afeb58&is=659d7658&hm=98878da6184eca24f9dedb85a9be58df3bc58ff490f54016f9f38111a91e7ef4&=&format=webp&quality=lossless\" width=\"500px\"> \\\n",
    "Это обеспечивается через\n",
    "`python\n",
    "prev_targets[:, 1:] = F.one_hot(new_dataset.targets[:, :-1], 10)\n",
    "new_dataset.data = torch.cat([new_dataset.data, prev_targets], dim=-1)\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и все аугментации. Идейно ничего сложного нет, но с точки зрения вычислений там есть, что пооптимизировать, хотя это можно глянуть в `datagen.py`. Пока бенчмарк такой - $2^{16}$ тасок генерируются за 2 минуты, но по памяти бьют сильно, потому что сохраняются локально, занимают почти 40Гб, как минимум вот эту штуку было бы хорошо переделать, чтобы читать лоадером из файла"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
